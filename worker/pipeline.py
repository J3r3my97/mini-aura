"""
Main image processing pipeline
Orchestrates: download ‚Üí bg removal (input) ‚Üí Claude analysis ‚Üí prompt generation ‚Üí Imagen ‚Üí bg removal (pixel art) ‚Üí compositing ‚Üí upload
"""
import time
import uuid
import logging
from typing import Dict, Any

from config import (
    GCS_UPLOAD_BUCKET,
    GCS_RESULT_BUCKET,
    MINI_ME_SCALE,
    MINI_ME_POSITION
)
from utils.firestore import update_job_status, get_job, get_user_for_job
from utils.gcs import download_from_gcs, upload_to_gcs
from utils.image_processing import remove_background, composite_images, add_watermark
from utils.ai import analyze_image_with_claude, generate_imagen_prompt, generate_pixel_art_with_imagen

logger = logging.getLogger(__name__)


async def run_pipeline(job_id: str) -> Dict[str, Any]:
    """
    Execute the full image processing pipeline

    Pipeline steps:
    1. Download input image from GCS
    2. Remove background from input photo (rembg)
    3. Analyze image with Claude Haiku (vision)
    4. Generate Imagen prompt with Claude Haiku
    5. Generate pixel art with Google Imagen 3
    6. Remove background from generated pixel art (rembg)
    7. Composite images (place mini-me on original)
    8. Add watermark if free tier
    9. Upload result to GCS

    Args:
        job_id: Job ID (UUID)

    Returns:
        Dictionary with output_url and metadata
    """
    start_time = time.time()
    logger.info(f"üöÄ Starting pipeline for job {job_id}")

    try:
        # Get job details
        job = await get_job(job_id)
        if not job:
            raise ValueError(f"Job {job_id} not found in Firestore")

        # STEP 1: Download input image from GCS
        logger.info(f"üì• Step 1/9: Downloading input image")
        input_blob_name = f"{job_id}.jpg"  # Assuming uploaded as JPG
        input_path = f"/tmp/{job_id}_input.jpg"

        await download_from_gcs(
            bucket_name=GCS_UPLOAD_BUCKET,
            blob_name=input_blob_name,
            local_path=input_path
        )

        # STEP 2: Remove background from input photo
        logger.info(f"üé® Step 2/9: Removing background from input photo")
        no_bg_path = await remove_background(input_path)

        # STEP 3: Analyze image with Claude
        logger.info(f"üîç Step 3/9: Analyzing image with Claude")
        analysis = await analyze_image_with_claude(no_bg_path)

        # STEP 4: Generate Imagen prompt
        logger.info(f"‚úçÔ∏è  Step 4/9: Generating Imagen prompt")
        prompt = await generate_imagen_prompt(analysis)

        # STEP 5: Generate pixel art with Imagen
        logger.info(f"üé® Step 5/9: Generating pixel art with Imagen")
        pixel_art_path = f"/tmp/{job_id}_pixel.png"
        await generate_pixel_art_with_imagen(prompt, pixel_art_path)

        # STEP 6: Remove background from generated pixel art
        logger.info(f"‚úÇÔ∏è  Step 6/9: Removing white background from pixel art")
        pixel_art_nobg_path = await remove_background(pixel_art_path)

        # STEP 7: Composite images
        logger.info(f"üñºÔ∏è  Step 7/9: Compositing images")
        composite_path = await composite_images(
            background_path=input_path,
            foreground_path=pixel_art_nobg_path,
            position=MINI_ME_POSITION,
            scale=MINI_ME_SCALE
        )

        # STEP 8: Add watermark if free tier
        logger.info(f"üíß Step 8/9: Checking watermark requirement")
        user = await get_user_for_job(job_id)

        if user and user.get("subscription_tier") == "free":
            logger.info("Adding watermark (free tier)")
            composite_path = await add_watermark(composite_path)
        else:
            logger.info("Skipping watermark (paid tier)")

        # STEP 9: Upload result to GCS
        logger.info(f"üì§ Step 9/9: Uploading result to GCS")
        result_blob_name = f"{job_id}.png"
        output_url = await upload_to_gcs(
            local_path=composite_path,
            bucket_name=GCS_RESULT_BUCKET,
            blob_name=result_blob_name
        )

        # Calculate processing time
        processing_time = int((time.time() - start_time) * 1000)

        # Prepare metadata
        metadata = {
            "detected_colors": analysis.get("primary_colors", []),
            "generated_prompt": prompt,
            "style": "jrpg-pixel-art",
            "processing_time_ms": processing_time
        }

        logger.info(f"‚úÖ Pipeline complete! Processing time: {processing_time}ms")

        return {
            "output_url": output_url,
            "metadata": metadata
        }

    except Exception as e:
        logger.error(f"‚ùå Pipeline failed for job {job_id}: {str(e)}")
        raise
